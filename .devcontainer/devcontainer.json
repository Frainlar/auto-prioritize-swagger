{
  "name": "Auto Prioritize Swagger",
  "image": "mcr.microsoft.com/devcontainers/javascript-node:20",
  // Add Git LFS as a devcontainer Feature (cleaner than ad-hoc apt)
  "features": {
    "ghcr.io/devcontainers/features/git-lfs:1": {}
  },
  // Make Ollama reachable + keep models in the workspace (survives rebuilds)
  "containerEnv": {
    "OLLAMA_HOST": "0.0.0.0:11434",
    "OLLAMA_MODELS": "/workspaces/.ollama"
  },
  "forwardPorts": [
    11434,
    3000,
    4000
  ],
  "portsAttributes": {
    "11434": {
      "label": "Ollama"
    },
    "3000": {
      "label": "Analyzer"
    },
    "4000": {
      "label": "Creator"
    }
  },
  // Install Ollama if missing; ensure model dir exists; run LFS install for hooks
  "postCreateCommand": "bash -lc 'mkdir -p /workspaces/.ollama && git lfs install && if ! command -v ollama >/dev/null; then curl -fsSL https://ollama.com/install.sh | sh; fi'",
  // Auto-start Ollama on each container start
  "postStartCommand": "bash -lc 'pgrep -x ollama >/dev/null || (nohup env OLLAMA_HOST=0.0.0.0:11434 OLLAMA_MODELS=/workspaces/.ollama ollama serve >/workspaces/ollama.log 2>&1 &)'",
  "customizations": {
    "vscode": {
      "extensions": [
        "GitHub.copilot",
        "GitHub.copilot-chat"
      ]
    }
  }
}